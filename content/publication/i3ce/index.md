---
title: 'An Empirical Analysis of Secure Federated Learning for Autonomous Vehicle Applications'

authors:
  - admin
  - M. Hadi Amini

date: '2024-08-08T00:00:00Z'
doi: 'https://doi.org/10.48550/arXiv.2509.20223'

publication_types: ['Conference paper']

publication: i3ce, 2024 ASCE International Conference on Computing in Civil Engineering
publication_short: i3ce, 2024

abstract: |
  Federated Learning lends itself as a promising paradigm for enabling distributed learning in autonomous vehicle applications, ensuring data privacy while enhancing predictive model performance through collaborative training on edge client vehicles. However, it remains vulnerable to various categories of cyber-attacks, necessitating more robust security measures to effectively mitigate potential threats. Poisoning and inference attacks are commonly initiated within the federated learning environment to compromise system security. Secure aggregation can limit the disclosure of sensitive information from both outsider and insider attackers. This study conducts an empirical analysis on the transportation image dataset (e.g., LISA traffic light) using various secure aggregation techniques and multiparty computation in the presence of diverse cyber-attacks. Multiparty computation serves as a state-of-the-art security mechanism, providing privacy-preserving aggregation of local model updates from autonomous vehicles through multiple security protocols. The findings demonstrate how adversaries can mislead autonomous vehicle models, causing traffic light misclassification and potential hazards. This study explores the resilience of different secure federated learning aggregation and multiparty computation methods in safeguarding autonomous vehicle applications against cyber threats during both training and inference phases.

summary: This study analyzes secure aggregation and multiparty computation methods in federated learning for autonomous vehicle applications. Using the LISA traffic light dataset, it evaluates their defense against poisoning and inference attacks, highlighting the effectiveness of multiparty computation in preserving privacy and improving model resilience during training and inference.
tags:
  - Privacy and security
  - Federated Learning
  - Machine Learning

featured: true

url_pdf: 'https://arxiv.org/pdf/2509.20223'

image:
  caption: 'An Empirical Analysis of Secure Federated Learning for Autonomous Vehicle Applications'
  focal_point: ''
  preview_only: false
---
